{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niklasgrimm98/Digital-Organization/blob/main/Homework_3_niklas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "fastbook.setup_book()"
      ],
      "metadata": {
        "id": "HhmY7I5M8VJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de26b1bf-fb45-449e-fe19-0f82a438ce48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Artificial Neural Networks\n",
        "\n",
        "Please read the introdcution of neuronal networks of the book *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow*, p. 299-316.\n",
        "\n",
        "Why have neural networks, even though they were invented early on, only now caught on?\n",
        "\n",
        "More avaiable data, greater computing power(Moores Law), better training algorithms, greater attention\n",
        "\n",
        "What is a percepton and a threshold logic unit (TLU)? Try to define a linear function and a step function of your choice, use some values of your choice and explain what might be the result of the percepton. (maybe using max. two TLU's)\n",
        "\n",
        "The TLU computes a function of the inputs multiplied with a weight. The values might be 2,3,5, the weights might be 0.3,0.5,0.2, so the function is 2*0,3+3*0.5+5*0.2 = 3.1. The step function is then used to determine the value. For example in a classification task with 2 classes, the step function determines in which categrorie the value falls. \n",
        "\n",
        "What is a fully connected layer and a output layer? Why can we easily combine the equations of multiple instances into a fully connected layer?\n",
        "\n",
        "A fully connected layer means that every TLU is connected to every input. The output layer produces the final output. \n",
        "\n",
        "\n",
        "What problem did Marvin Minsky and Seymour Paper highlight that perceptrons could not solve? What is a possible solution?\n",
        "\n",
        "Perceptrons could not solve trivial classifaction problems, especially linear clasissifacition. The possible solution is stakcing multiple perceptrons, creating a ANN, which can solve the XOR problem. \n",
        "\n",
        "What is a deep neuronal network? What are hidden layers? What means feedforward neural network (FNN).\n",
        "\n",
        "FNN means the signal only flows in one direction, from the inputs to the outputs. A DNN contains a deep stack of hidden layers. Hidden layers are layers between in and output. \n",
        "\n",
        "Try to explain how backpropagation works! (In Addition, you can have a look to the following example, which tries manually to compute the backprogation of a simple linear network. https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ OR you can also read through the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy))\n",
        "\n",
        "Backpropagation is used to train a machine learning model. It works one mini batch at a time. First comes the foreward pass, the the algorithm measures the networks output error. Then the reverse pass measurer where the errors came from and finally the algorhtims tweaks all the weights to reduce the error. \n",
        "\n",
        "Why do we need activation functions, wouldn't it be easier just using linear functions?\n",
        "\n",
        "We need to activation function to model non-linear relationships. Without the activation function, only linear porblems could be solved. \n",
        "\n",
        "## Ideas for the learning portfolio: \n",
        "\n",
        "1) For example, you could train a single TLU to classify iris flowers based on petal length and width in the !!!pyTorch!! environment.\n",
        "\n",
        "2) You could add to our king county housepricing ML project a neuronal network and compare it to the other models. "
      ],
      "metadata": {
        "id": "_Rdj49uwjuoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "4tF8YDV3T91n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A traditional approach: training a digit classifier and learning pyTorch tensors.\n",
        "\n",
        "For this assignment, I ask you to read the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy) to the beginning of the chapter *Stochastic Gradient Descent (SGD)*. \n",
        "\n",
        "First, try to summarize what we know about pyTorch tensors by trying to predict whether we have a 1 or a 7 in the MNIST dataset using a traditional rule-based programming approach. Therefore use pyTorch tensors for the entire tasks and fulfill the following steps:\n",
        "\n",
        "1) Randomly split the MNIST dataset (1 and 7) into a training dataset and a test dataset in a ratio of 80:20.\n",
        "\n",
        "2) Instead of using an optimal 1 or 7 with the mean over the training dataset, try to calculate the sum of the distances to all instances in the training set for each instance in the test dataset. You can use the L2 norm. \n",
        "\n",
        "3) For each instance in the test set, decide if it is a 1 or 7 and calculate the precision.\n",
        "\n",
        "Do we get a similar good result?\n"
      ],
      "metadata": {
        "id": "h6OwXNEeed93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "metadata": {
        "id": "OmZlG1jkHDrS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Hrrgv9OVebAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "dce02c75-8da3-403f-98fb-11622ee01326"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:01&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# YOUR TASK\n",
        "path = untar_data(URLs.MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path.BASE_PATH = path"
      ],
      "metadata": {
        "id": "uFcMNONVHXB1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiI0t2QjHiyM",
        "outputId": "e8945b9c-139d-4478-e991-626d30fb3625"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = ((path/'training'/'1').ls() + (path/'testing'/'1').ls()).sorted()\n",
        "sevens = ((path/'training'/'7').ls() + (path/'testing'/'7').ls()).sorted()"
      ],
      "metadata": {
        "id": "L23KZ_9JIhag"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im1_path = ones[1]\n",
        "im1 = Image.open(im1_path)\n",
        "im1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "HNoERaHqI8GC",
        "outputId": "0cb0c473-a9b3-4299-f239-ce7af68ea999"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAcUlEQVR4nGNgGGDAFHdAA6ekxL9/G1EU4zWJaEktfJLSDAzTcUrqMDAk4pRkZWCYRJ6DGBgY8Un+V8GnUw2fztf4HOSIU3IPmoNQAOfBf0+kcen8fp9Big+nnbcYGNRxmit++99RTtyuZVj1E7eb6AEA2VAUiHLf028AAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im1_t = tensor(im1)\n",
        "df = pd.DataFrame(im1_t[4:15,4:22])\n",
        "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "wKwmg7NpJLRP",
        "outputId": "b239e476-f57c-4a16-b2cf-45223e1d0a34"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fb453acc550>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_8868c_row0_col0, #T_8868c_row0_col1, #T_8868c_row0_col2, #T_8868c_row0_col3, #T_8868c_row0_col4, #T_8868c_row0_col5, #T_8868c_row0_col6, #T_8868c_row0_col7, #T_8868c_row0_col8, #T_8868c_row0_col9, #T_8868c_row0_col10, #T_8868c_row0_col11, #T_8868c_row0_col12, #T_8868c_row0_col13, #T_8868c_row0_col14, #T_8868c_row0_col15, #T_8868c_row0_col16, #T_8868c_row0_col17, #T_8868c_row1_col0, #T_8868c_row1_col1, #T_8868c_row1_col2, #T_8868c_row1_col3, #T_8868c_row1_col4, #T_8868c_row1_col5, #T_8868c_row1_col6, #T_8868c_row1_col7, #T_8868c_row1_col12, #T_8868c_row1_col13, #T_8868c_row1_col14, #T_8868c_row1_col15, #T_8868c_row1_col16, #T_8868c_row1_col17, #T_8868c_row2_col0, #T_8868c_row2_col1, #T_8868c_row2_col2, #T_8868c_row2_col3, #T_8868c_row2_col4, #T_8868c_row2_col5, #T_8868c_row2_col6, #T_8868c_row2_col7, #T_8868c_row2_col12, #T_8868c_row2_col13, #T_8868c_row2_col14, #T_8868c_row2_col15, #T_8868c_row2_col16, #T_8868c_row2_col17, #T_8868c_row3_col0, #T_8868c_row3_col1, #T_8868c_row3_col2, #T_8868c_row3_col3, #T_8868c_row3_col4, #T_8868c_row3_col5, #T_8868c_row3_col6, #T_8868c_row3_col7, #T_8868c_row3_col12, #T_8868c_row3_col13, #T_8868c_row3_col14, #T_8868c_row3_col15, #T_8868c_row3_col16, #T_8868c_row3_col17, #T_8868c_row4_col0, #T_8868c_row4_col1, #T_8868c_row4_col2, #T_8868c_row4_col3, #T_8868c_row4_col4, #T_8868c_row4_col5, #T_8868c_row4_col6, #T_8868c_row4_col7, #T_8868c_row4_col12, #T_8868c_row4_col13, #T_8868c_row4_col14, #T_8868c_row4_col15, #T_8868c_row4_col16, #T_8868c_row4_col17, #T_8868c_row5_col0, #T_8868c_row5_col1, #T_8868c_row5_col2, #T_8868c_row5_col3, #T_8868c_row5_col4, #T_8868c_row5_col5, #T_8868c_row5_col6, #T_8868c_row5_col7, #T_8868c_row5_col12, #T_8868c_row5_col13, #T_8868c_row5_col14, #T_8868c_row5_col15, #T_8868c_row5_col16, #T_8868c_row5_col17, #T_8868c_row6_col0, #T_8868c_row6_col1, #T_8868c_row6_col2, #T_8868c_row6_col3, #T_8868c_row6_col4, #T_8868c_row6_col5, #T_8868c_row6_col6, #T_8868c_row6_col7, #T_8868c_row6_col12, #T_8868c_row6_col13, #T_8868c_row6_col14, #T_8868c_row6_col15, #T_8868c_row6_col16, #T_8868c_row6_col17, #T_8868c_row7_col0, #T_8868c_row7_col1, #T_8868c_row7_col2, #T_8868c_row7_col3, #T_8868c_row7_col4, #T_8868c_row7_col5, #T_8868c_row7_col6, #T_8868c_row7_col7, #T_8868c_row7_col12, #T_8868c_row7_col13, #T_8868c_row7_col14, #T_8868c_row7_col15, #T_8868c_row7_col16, #T_8868c_row7_col17, #T_8868c_row8_col0, #T_8868c_row8_col1, #T_8868c_row8_col2, #T_8868c_row8_col3, #T_8868c_row8_col4, #T_8868c_row8_col5, #T_8868c_row8_col6, #T_8868c_row8_col7, #T_8868c_row8_col12, #T_8868c_row8_col13, #T_8868c_row8_col14, #T_8868c_row8_col15, #T_8868c_row8_col16, #T_8868c_row8_col17, #T_8868c_row9_col0, #T_8868c_row9_col1, #T_8868c_row9_col2, #T_8868c_row9_col3, #T_8868c_row9_col4, #T_8868c_row9_col5, #T_8868c_row9_col6, #T_8868c_row9_col7, #T_8868c_row9_col12, #T_8868c_row9_col13, #T_8868c_row9_col14, #T_8868c_row9_col15, #T_8868c_row9_col16, #T_8868c_row9_col17, #T_8868c_row10_col0, #T_8868c_row10_col1, #T_8868c_row10_col2, #T_8868c_row10_col3, #T_8868c_row10_col4, #T_8868c_row10_col5, #T_8868c_row10_col6, #T_8868c_row10_col7, #T_8868c_row10_col12, #T_8868c_row10_col13, #T_8868c_row10_col14, #T_8868c_row10_col15, #T_8868c_row10_col16, #T_8868c_row10_col17 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #ffffff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8868c_row1_col8, #T_8868c_row2_col8, #T_8868c_row3_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #eaeaea;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8868c_row1_col9, #T_8868c_row1_col11, #T_8868c_row2_col9, #T_8868c_row2_col11, #T_8868c_row3_col9, #T_8868c_row3_col11, #T_8868c_row4_col9, #T_8868c_row4_col11, #T_8868c_row5_col9, #T_8868c_row6_col9, #T_8868c_row7_col8, #T_8868c_row7_col9, #T_8868c_row8_col8, #T_8868c_row8_col9, #T_8868c_row9_col8, #T_8868c_row9_col9, #T_8868c_row9_col10, #T_8868c_row10_col8, #T_8868c_row10_col9 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #000000;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8868c_row1_col10, #T_8868c_row2_col10, #T_8868c_row3_col10, #T_8868c_row4_col10, #T_8868c_row5_col10, #T_8868c_row6_col10, #T_8868c_row7_col10, #T_8868c_row8_col10, #T_8868c_row10_col10 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #050505;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8868c_row4_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #a3a3a3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8868c_row5_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #6c6c6c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8868c_row5_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #dcdcdc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8868c_row6_col8 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #0a0a0a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8868c_row6_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #101010;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8868c_row7_col11, #T_8868c_row8_col11, #T_8868c_row9_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #eeeeee;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8868c_row10_col11 {\n",
              "  font-size: 6pt;\n",
              "  background-color: #b5b5b5;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_8868c\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_8868c_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
              "      <th id=\"T_8868c_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
              "      <th id=\"T_8868c_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
              "      <th id=\"T_8868c_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
              "      <th id=\"T_8868c_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
              "      <th id=\"T_8868c_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
              "      <th id=\"T_8868c_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
              "      <th id=\"T_8868c_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
              "      <th id=\"T_8868c_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
              "      <th id=\"T_8868c_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
              "      <th id=\"T_8868c_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
              "      <th id=\"T_8868c_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
              "      <th id=\"T_8868c_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
              "      <th id=\"T_8868c_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
              "      <th id=\"T_8868c_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
              "      <th id=\"T_8868c_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
              "      <th id=\"T_8868c_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
              "      <th id=\"T_8868c_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_8868c_row0_col0\" class=\"data row0 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col2\" class=\"data row0 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col4\" class=\"data row0 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col5\" class=\"data row0 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col6\" class=\"data row0 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col7\" class=\"data row0 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col8\" class=\"data row0 col8\" >2</td>\n",
              "      <td id=\"T_8868c_row0_col9\" class=\"data row0 col9\" >94</td>\n",
              "      <td id=\"T_8868c_row0_col10\" class=\"data row0 col10\" >192</td>\n",
              "      <td id=\"T_8868c_row0_col11\" class=\"data row0 col11\" >40</td>\n",
              "      <td id=\"T_8868c_row0_col12\" class=\"data row0 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col13\" class=\"data row0 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col14\" class=\"data row0 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col15\" class=\"data row0 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col16\" class=\"data row0 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row0_col17\" class=\"data row0 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_8868c_row1_col0\" class=\"data row1 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col4\" class=\"data row1 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col5\" class=\"data row1 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col6\" class=\"data row1 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col7\" class=\"data row1 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col8\" class=\"data row1 col8\" >24</td>\n",
              "      <td id=\"T_8868c_row1_col9\" class=\"data row1 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row1_col10\" class=\"data row1 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row1_col11\" class=\"data row1 col11\" >177</td>\n",
              "      <td id=\"T_8868c_row1_col12\" class=\"data row1 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col13\" class=\"data row1 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col14\" class=\"data row1 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col15\" class=\"data row1 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col16\" class=\"data row1 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row1_col17\" class=\"data row1 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_8868c_row2_col0\" class=\"data row2 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col2\" class=\"data row2 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col3\" class=\"data row2 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col4\" class=\"data row2 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col5\" class=\"data row2 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col6\" class=\"data row2 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col7\" class=\"data row2 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col8\" class=\"data row2 col8\" >24</td>\n",
              "      <td id=\"T_8868c_row2_col9\" class=\"data row2 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row2_col10\" class=\"data row2 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row2_col11\" class=\"data row2 col11\" >177</td>\n",
              "      <td id=\"T_8868c_row2_col12\" class=\"data row2 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col13\" class=\"data row2 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col14\" class=\"data row2 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col15\" class=\"data row2 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col16\" class=\"data row2 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row2_col17\" class=\"data row2 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_8868c_row3_col0\" class=\"data row3 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col2\" class=\"data row3 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col3\" class=\"data row3 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col4\" class=\"data row3 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col5\" class=\"data row3 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col6\" class=\"data row3 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col7\" class=\"data row3 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col8\" class=\"data row3 col8\" >24</td>\n",
              "      <td id=\"T_8868c_row3_col9\" class=\"data row3 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row3_col10\" class=\"data row3 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row3_col11\" class=\"data row3 col11\" >177</td>\n",
              "      <td id=\"T_8868c_row3_col12\" class=\"data row3 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col13\" class=\"data row3 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col14\" class=\"data row3 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col15\" class=\"data row3 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col16\" class=\"data row3 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row3_col17\" class=\"data row3 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_8868c_row4_col0\" class=\"data row4 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col2\" class=\"data row4 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col3\" class=\"data row4 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col4\" class=\"data row4 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col5\" class=\"data row4 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col6\" class=\"data row4 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col7\" class=\"data row4 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col8\" class=\"data row4 col8\" >66</td>\n",
              "      <td id=\"T_8868c_row4_col9\" class=\"data row4 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row4_col10\" class=\"data row4 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row4_col11\" class=\"data row4 col11\" >177</td>\n",
              "      <td id=\"T_8868c_row4_col12\" class=\"data row4 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col13\" class=\"data row4 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col14\" class=\"data row4 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col15\" class=\"data row4 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col16\" class=\"data row4 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row4_col17\" class=\"data row4 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_8868c_row5_col0\" class=\"data row5 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col2\" class=\"data row5 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col3\" class=\"data row5 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col4\" class=\"data row5 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col5\" class=\"data row5 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col6\" class=\"data row5 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col7\" class=\"data row5 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col8\" class=\"data row5 col8\" >93</td>\n",
              "      <td id=\"T_8868c_row5_col9\" class=\"data row5 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row5_col10\" class=\"data row5 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row5_col11\" class=\"data row5 col11\" >72</td>\n",
              "      <td id=\"T_8868c_row5_col12\" class=\"data row5 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col13\" class=\"data row5 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col14\" class=\"data row5 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col15\" class=\"data row5 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col16\" class=\"data row5 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row5_col17\" class=\"data row5 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_8868c_row6_col0\" class=\"data row6 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col2\" class=\"data row6 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col3\" class=\"data row6 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col4\" class=\"data row6 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col5\" class=\"data row6 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col6\" class=\"data row6 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col7\" class=\"data row6 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col8\" class=\"data row6 col8\" >137</td>\n",
              "      <td id=\"T_8868c_row6_col9\" class=\"data row6 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row6_col10\" class=\"data row6 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row6_col11\" class=\"data row6 col11\" >169</td>\n",
              "      <td id=\"T_8868c_row6_col12\" class=\"data row6 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col13\" class=\"data row6 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col14\" class=\"data row6 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col15\" class=\"data row6 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col16\" class=\"data row6 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row6_col17\" class=\"data row6 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_8868c_row7_col0\" class=\"data row7 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col2\" class=\"data row7 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col3\" class=\"data row7 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col4\" class=\"data row7 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col5\" class=\"data row7 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col6\" class=\"data row7 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col7\" class=\"data row7 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col8\" class=\"data row7 col8\" >142</td>\n",
              "      <td id=\"T_8868c_row7_col9\" class=\"data row7 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row7_col10\" class=\"data row7 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row7_col11\" class=\"data row7 col11\" >59</td>\n",
              "      <td id=\"T_8868c_row7_col12\" class=\"data row7 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col13\" class=\"data row7 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col14\" class=\"data row7 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col15\" class=\"data row7 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col16\" class=\"data row7 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row7_col17\" class=\"data row7 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_8868c_row8_col0\" class=\"data row8 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col2\" class=\"data row8 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col3\" class=\"data row8 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col4\" class=\"data row8 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col5\" class=\"data row8 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col6\" class=\"data row8 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col7\" class=\"data row8 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col8\" class=\"data row8 col8\" >142</td>\n",
              "      <td id=\"T_8868c_row8_col9\" class=\"data row8 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row8_col10\" class=\"data row8 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row8_col11\" class=\"data row8 col11\" >59</td>\n",
              "      <td id=\"T_8868c_row8_col12\" class=\"data row8 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col13\" class=\"data row8 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col14\" class=\"data row8 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col15\" class=\"data row8 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col16\" class=\"data row8 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row8_col17\" class=\"data row8 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_8868c_row9_col0\" class=\"data row9 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col2\" class=\"data row9 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col3\" class=\"data row9 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col4\" class=\"data row9 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col5\" class=\"data row9 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col6\" class=\"data row9 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col7\" class=\"data row9 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col8\" class=\"data row9 col8\" >142</td>\n",
              "      <td id=\"T_8868c_row9_col9\" class=\"data row9 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row9_col10\" class=\"data row9 col10\" >255</td>\n",
              "      <td id=\"T_8868c_row9_col11\" class=\"data row9 col11\" >59</td>\n",
              "      <td id=\"T_8868c_row9_col12\" class=\"data row9 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col13\" class=\"data row9 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col14\" class=\"data row9 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col15\" class=\"data row9 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col16\" class=\"data row9 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row9_col17\" class=\"data row9 col17\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8868c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_8868c_row10_col0\" class=\"data row10 col0\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col2\" class=\"data row10 col2\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col3\" class=\"data row10 col3\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col4\" class=\"data row10 col4\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col5\" class=\"data row10 col5\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col6\" class=\"data row10 col6\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col7\" class=\"data row10 col7\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col8\" class=\"data row10 col8\" >142</td>\n",
              "      <td id=\"T_8868c_row10_col9\" class=\"data row10 col9\" >254</td>\n",
              "      <td id=\"T_8868c_row10_col10\" class=\"data row10 col10\" >254</td>\n",
              "      <td id=\"T_8868c_row10_col11\" class=\"data row10 col11\" >95</td>\n",
              "      <td id=\"T_8868c_row10_col12\" class=\"data row10 col12\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col13\" class=\"data row10 col13\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col14\" class=\"data row10 col14\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col15\" class=\"data row10 col15\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col16\" class=\"data row10 col16\" >0</td>\n",
              "      <td id=\"T_8868c_row10_col17\" class=\"data row10 col17\" >0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_tensors = [tensor(Image.open(o)) for o in ones]\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "len(one_tensors), len(seven_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgdIPfT5KT4c",
        "outputId": "1bc9fe26-c7df-4df2-be14-a250d2f7a8db"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7877, 7293)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_ones = torch.stack(one_tensors).float()/255\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_ones.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4VIW5JeKnSG",
        "outputId": "dc54fd74-b382-463f-92b1-1852a64fdeec"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7877, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_1 = stacked_ones[1]\n",
        "a_7 = stacked_sevens[1]\n",
        "show_image(a_1);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "-nYeOosNMFUV",
        "outputId": "013130c2-653a-4e0c-f08d-1406a4f1d4a6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean1 = stacked_ones.mean(0)\n",
        "mean7 = stacked_sevens.mean(0)\n",
        "show_image(mean1);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "zbqdcF5RK7q0",
        "outputId": "d0b1105a-79a2-434e-c47c-963157523ba9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAIrUlEQVR4nO1c2XLiSBBMdIPAQIzn/39vHmwzHEJC5z5MZLvU0zLM7ILKa2UEIYHF4cquu1qzrus6TBgV3tg/YMJEggpMJCjARIICTCQowESCAkwkKMBEggJMJCjARIICTCQowESCAkwkKMBEggJMJCjARIICTCQoQDD2D/i3uNYYnM1mD/olf49PS8KtXdmh6zSRo54EKUSed13XO7evc0EK3XVuH13X3gsqSRgSfNu25jh0bmM2m/UE7Hp4ntc7l9d2XTdI0H8FlSTY4MqXj6ZpzLGu69+IcK1wz/Pg+z4AwPd9J0Gu98rfcQ8iVJNgC56CrusaVVWhbVuUZWnOm6ZxksDV7fs+fN+H53kIgsCcy+ukkKVG3tMsqSPBZetJAIVcVRXyPEfTNCiKAufzGV3XoSxL1HUN4F1oFLTneQjDEFEUYTabIY5jQ0qSJEZLpFm618q3oYqEIedqEyJJoTlqmsZJAle9tPu+76NpGvO8bVtj/68J/h7EqCLBBRcBFHxd17hcLiiKAm3bIs9zXC4XAO8kcPX7vm8+q2kaQwxXPP92TcBf0ie4Xmvbtrf6L5cLqqpClmUoigLAu7CiKEKSJMYhU/AkwhVRPRqqSbBhk8IVzOiI2gH0zVHTNL3rXRgzeVNNwpBgmBs0TYOqqgY1gfaeDphk8O/UCum8h3KJe0I1CQCMw7QhE7WqqlCWJcqyRFEUvQjH8zxEUQQAJsTl59qJ2qOFT6gnQcKO4SUJ8sEIiNoi309i7Mctwv/SGbPrn+eqrqoKRVGgKApkWYYsy3phqed5qOva5AC+7yMIAgRBgDAMe0nbR2R8qWTtVkinXFWVOZZl2cuQGf0wvr9FCx5pigBFJNxaBaWPsB0ztaEoChOOhmFoEjGXBkgt+Ej4X9YxDzlkoO8P8jw3UdHpdMLxeEQQ/Pq3eI3v+0bwURQhDEPz3KUR/H55vCfUkkB8ZJftxI15AkNT+g07Wrpm9x9JAKCox/wn/7D0Befz2WgAHyzuAb+StTiOkSQJ4jg2jzAMew7Z1oRHQr0mDIHFO5ojHvf7Pbquw2azQdd18DwPSZIgSZKrpkjikWSo0YRrsHMEWchjfsAqKrVANnKGMmPXdzxaGz6lJrCZcz6fcTgc8Pb2hqIosNvtkGUZ4jjGbDZDEARIkgRpmmKxWBiNkITYvmEyRzdCliryPMfhcDDJ2vl8RlmWhoQoihBF0W9+wO4ny+Oj8SlIsIXTtq3JDS6XC87nM4qiQF3XJqxlWEoSbEc8tuAlPgUJhMyS9/s9drsdfv78iR8/fqCqqt61cRwjTVOs12ukaWpMkfQPY5shQr1jdgmnaRpcLhfzoEZwAgN41wRGQmEYDmrB2NqgmgSZNctSRVmWOBwOOBwOyLLMkMGQNIoiLBYLLJdLpGmKOI5Ni3OM2tA1fBpzRBKYoL2+vuLl5QUvLy84nU4Afpmg+XyOJEmwXq/x7ds3LJdLkyPcUicaA5+GBKCfH3D1V1VlJicAGHvPyEir4CVUmyN70oL2/3A4YL/f43A44HQ6GV8QRRHSNEWapthut1iv11gsFs5BL01QRYJLOHLOiO1LkvD6+oosy8xQWBiGSNMU8/kcm80Gq9UK8/m8N3mnxRlLqCLBBXvYS5Ynqqoy2sJuGp0wcwNXXUgbVPkEexrb7iMfj0eTHxyPR5xOJ1RVZQjYbrd4fn7Ger3GcrnEfD5HHMcqEzSJT6EJ1IA8z3E6nUx5gpN3JGGxWCBNUyyXS6MRQRA8rFf8t1BJgq0FMj/I89yYIeYFLE/QHyRJ0ps/BaA2MgIUmSPbFEkzxOLcbrfD29sbTqcTyrJE0zTGGS+XS2y3W3z//h3Pz89IkuTT+AR1muDaDMK+ARv5ds+AOUGSJKZkPWan7E+hQhNcexKkCZKTFCRBbvRgSEqfsFgsTInC9V3aiBmdhI9G37kJJMsy00dmv4A1IvaMt9stNpsNttstVqvVb1VSOf6ojQhV5si1O8e1GYQOmaaIkRCrprf4AU03Rh5VE1xClyEpTVGe5yYqYp2IJufp6clUSxkdhWHY04Chla9FI0YjwfYDck6IvoAh6fl8RpZlvbki1oRWqxVWq5XxBXEcm+Ev11Zc1+yS6/VHYhQSXJs95LmdH9g7M1klBWAaNnKMxSXoW8zTl+kxuwRu70dmtZTmiM6YggrDEMvlEm3b4unpCavVyoSmLNbx86XGySaRJvP0UBJctSF7RybHGmmOeM4esnTGXdeZ3EDWiWx/IAnQ4ANsjGaOhghgJCTNECMimqG6rhFFEbquu2qK5HfaA2RaCHkYCa58wBa+XPnsmskGvu/7iKLIdM+6rjPVUlmmAGA+U26dlebpVrIegdHMEZ/bSRqFx0iIJAHv2185SQGgt9fA3sNwy+/RoA13J2FI8PZdWqQZIhm28IMgMO/hireHu1wzq3Y4rA0PNUcyJ7BDUa58uf1J7i/wfd/cj4L9ZADGIbOpL7+P75crXsvqlxg1ROVzSciQ/SYRtlBdo43/Bv+7EHVI/V3O2X6NgmfDRjpcSZbcdyAJsX+DVlMEPEgTbAHbr0kS5P2KSALvQ8Fd+VKgMkS1Jyrk94+xIfBWjF7KBn6/QRSPDEu5CxOAuSkIiZCzpkOjLbc2d75M2cIlHNp7hplJkgCAmSVidmz7DKAftnLymtphR0wfEfLlCngSXPXSlsvVb4emtm2XW6JYQaVpsgeAh0bhxzZLDyFhqFxgRzUUsrxhIHMGlz/hZ5AIhqlSC0iEdNbaMOvuHDa4avqunMFO4FxJ1keRDk2a1AypZbxG4wDY3UkgrpEhIyP5uuv9rue2yRnaNK5J+MQoPsG2xzIvGFrtt6wVKWzX6teKh2nCEP706z+6XlvUcytGJ2GCspGXr4qJBAWYSFCAiQQFmEhQgIkEBZhIUICJBAWYSFCAiQQFmEhQgIkEBZhIUICJBAWYSFCAiQQF+AdrLyAbwyxg3gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist_1_sqr = ((a_1 - mean1)**2).mean().sqrt()\n",
        "dist_1_sqr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "976V4zf2K_vP",
        "outputId": "15bb2465-afde-43c9-99f1-0be253042a51"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1640)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for every instance in test data set, calculate distance to all training instances\n",
        "\n",
        "#Split Data into Test and Train\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ones_train, ones_test = train_test_split(stacked_ones, test_size=0.2, random_state = 10)\n",
        "sevens_train, sevens_test = train_test_split(stacked_sevens, test_size=0.2, random_state = 10)\n"
      ],
      "metadata": {
        "id": "q7WEuKAkMfCF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_1_inner_loop = 0 \n",
        "for i in range(len(ones_test)):\n",
        "  dist_1_loop = 0\n",
        "  for j in range(len(ones_train)):\n",
        "    dist_1_sqr = ((ones_test[i] - ones_train[j])**2).mean().sqrt()\n",
        "    dist_1_loop = dist_1_loop + dist_1_sqr\n",
        "  dist_1_inner_loop = dist_1_inner_loop + dist_1_loop/len(ones_train)\n",
        "\n",
        "result = dist_1_inner_loop/len(ones_test)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_nSgA28Mzgv",
        "outputId": "4a07c863-263e-47ee-985c-7064697df697"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2306)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist_7_inner_loop = 0 \n",
        "for i in range(len(sevens_test)):\n",
        "  dist_7_loop = 0\n",
        "  for j in range(len(sevens_train)):\n",
        "    dist_7_sqr = ((sevens_test[i] - sevens_train[j])**2).mean().sqrt()\n",
        "    dist_7_loop = dist_7_loop + dist_7_sqr\n",
        "  dist_7_inner_loop = dist_7_inner_loop + dist_7_loop/len(sevens_train)\n",
        "\n",
        "result2 = dist_1_inner_loop/len(sevens_test)\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuX8fbBoPCBe",
        "outputId": "0b135514-be51-4677-b798-454f96811e55"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2491)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
        "valid_1_dist = mnist_distance(ones_test, mean1)\n",
        "valid_1_dist, valid_1_dist.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgK9fngOPYMp",
        "outputId": "45121dbf-e9b6-47d5-83b1-59aca5440e96"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0697, 0.0702, 0.0825,  ..., 0.0575, 0.0699, 0.0569]),\n",
              " torch.Size([1576]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_1(x): return mnist_distance(x,mean1) < mnist_distance(x,mean7)\n",
        "is_1(a_1), is_1(a_1).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4D__y6_TIZm",
        "outputId": "895f5b50-f2e6-47a9-803b-ea7b7c9fbc68"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(True), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_1s =      is_1(ones_test).float() .mean()\n",
        "accuracy_7s = (1 - is_1(sevens_test).float()).mean()\n",
        "accuracy_1s,accuracy_7s,(accuracy_1s+accuracy_7s)/2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GehNNeHRTuFQ",
        "outputId": "edb84d1e-a8be-4b38-f208-0c64fa8c82a8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9994), tensor(0.8163), tensor(0.9078))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent (SGD)\n",
        "\n",
        "For this exercise I ask you to read the chapter Stochastic Gradient Descent (SGD) from the Google Colab 04_mnist_basics.ipynb in paralell. The chapter starts with a single TLU, compare p. 304 in \"Hands on Machine Learning\". Go through all 7 steps which are an easy example of how Stochastic Gradient Descent works.\n",
        "\n",
        "Our goal is to train a single TLU, which can decide if one number is larger then the other one. Therefore we create 100 random pairs with pyTorch and create a target vector which is eather 1 or 0.\n"
      ],
      "metadata": {
        "id": "ETcE9B9rdcEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((100, 2))\n",
        "y = torch.where(x[:,0] > x[:,1], 1.0, 0.0)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "17qLyDnbpSbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c50ee2-e0fe-4cdf-d345-e05fd9b90185"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3032e+00,  4.8787e-01],\n",
            "        [ 1.1340e+00, -3.5556e-01],\n",
            "        [ 3.6183e-01,  1.9993e+00],\n",
            "        [ 6.6301e-01,  7.0473e-01],\n",
            "        [ 2.1274e-02, -8.2927e-01],\n",
            "        [-1.0809e+00, -7.8385e-01],\n",
            "        [ 5.0710e-01,  8.2078e-02],\n",
            "        [ 4.4398e-01, -7.2403e-01],\n",
            "        [-4.6113e-01, -6.3885e-02],\n",
            "        [-1.3667e+00,  3.2982e-01],\n",
            "        [-9.8271e-01,  3.0177e-01],\n",
            "        [ 1.7869e-01, -1.2931e-01],\n",
            "        [-1.5754e+00,  2.2508e+00],\n",
            "        [ 1.0012e+00,  1.3642e+00],\n",
            "        [ 6.3332e-01,  4.0500e-01],\n",
            "        [ 3.4159e-01, -2.2136e-01],\n",
            "        [ 1.7290e-01,  1.0514e+00],\n",
            "        [ 7.4915e-03, -7.7365e-02],\n",
            "        [ 6.4269e-01,  5.7425e-01],\n",
            "        [ 5.8672e-01, -1.8847e-02],\n",
            "        [-9.1432e-01,  1.4840e+00],\n",
            "        [-9.1091e-01, -5.2910e-01],\n",
            "        [-8.0515e-01,  5.1580e-01],\n",
            "        [-7.1288e-01,  2.1962e-01],\n",
            "        [ 5.6351e-01,  1.8582e+00],\n",
            "        [ 1.0441e+00, -8.6382e-01],\n",
            "        [ 8.3509e-01, -3.1571e-01],\n",
            "        [ 2.6911e-01,  8.5404e-02],\n",
            "        [-1.4129e+00, -1.8791e+00],\n",
            "        [-1.7983e-01,  7.9039e-01],\n",
            "        [ 5.2394e-01, -2.6935e-01],\n",
            "        [-1.6191e+00,  1.2588e-03],\n",
            "        [ 8.6374e-01, -5.8900e-01],\n",
            "        [-1.0340e+00, -2.1787e-01],\n",
            "        [ 7.9865e-01,  9.1047e-01],\n",
            "        [-8.8018e-02,  3.3700e-01],\n",
            "        [-4.8076e-01,  3.1630e-01],\n",
            "        [ 3.8657e-01,  7.3369e-01],\n",
            "        [ 2.5103e-01,  7.6999e-02],\n",
            "        [-2.0634e-01,  2.1698e+00],\n",
            "        [ 5.2296e-01,  9.7173e-01],\n",
            "        [-2.7785e-01, -6.1160e-01],\n",
            "        [-5.5719e-01, -9.6835e-01],\n",
            "        [ 8.7128e-01, -9.5641e-02],\n",
            "        [ 3.4628e-01, -5.4016e-01],\n",
            "        [ 8.5686e-01, -6.7205e-01],\n",
            "        [ 1.0682e+00, -2.5272e-01],\n",
            "        [-1.8815e-01, -7.7115e-01],\n",
            "        [ 2.1368e-01, -1.2351e+00],\n",
            "        [ 1.8592e+00,  5.6125e-02],\n",
            "        [ 7.6942e-01,  2.5574e+00],\n",
            "        [ 5.7161e-01,  1.3596e+00],\n",
            "        [ 3.0397e-01,  9.3390e-01],\n",
            "        [-1.9726e+00, -1.4120e+00],\n",
            "        [ 1.7361e+00,  1.8350e+00],\n",
            "        [ 8.8002e-01,  5.6080e-02],\n",
            "        [-4.5604e-01, -6.1913e-02],\n",
            "        [-2.2219e-01, -1.2470e+00],\n",
            "        [-4.8619e-01, -3.3600e-01],\n",
            "        [ 3.6716e-02,  4.9340e-01],\n",
            "        [ 1.8576e-01, -9.6980e-01],\n",
            "        [ 1.8932e+00,  4.4469e-01],\n",
            "        [ 1.3637e-01,  3.0880e-01],\n",
            "        [ 1.6617e+00,  1.7512e-01],\n",
            "        [ 3.2731e-01,  1.2922e-01],\n",
            "        [ 2.8520e+00, -7.4357e-01],\n",
            "        [ 1.9537e-01, -1.3350e+00],\n",
            "        [ 3.9451e-01,  1.7060e+00],\n",
            "        [-3.0713e-01, -7.1550e-01],\n",
            "        [ 7.6167e-02, -2.1271e-01],\n",
            "        [-5.6626e-01,  3.9892e-01],\n",
            "        [ 1.3695e+00, -2.5189e-01],\n",
            "        [ 8.4787e-01, -6.9534e-01],\n",
            "        [ 3.0562e-01,  2.9091e-01],\n",
            "        [ 4.0854e-01, -1.2609e+00],\n",
            "        [ 9.1652e-01, -2.8006e-02],\n",
            "        [ 1.7868e-01, -3.8506e-02],\n",
            "        [-8.6883e-02, -1.1803e+00],\n",
            "        [ 1.5460e+00,  5.4476e-01],\n",
            "        [ 9.9346e-01,  5.0667e-01],\n",
            "        [-1.3351e+00,  1.6516e+00],\n",
            "        [ 1.9810e+00, -1.0479e-01],\n",
            "        [ 4.9029e-01, -4.3747e-01],\n",
            "        [-1.2201e+00, -5.8542e-01],\n",
            "        [-5.8936e-02, -4.8092e-01],\n",
            "        [ 9.9334e-01,  2.6951e-01],\n",
            "        [-1.8316e+00,  3.5699e-01],\n",
            "        [ 9.1429e-01,  2.1882e+00],\n",
            "        [-1.2311e+00,  8.6572e-01],\n",
            "        [-1.4236e+00, -6.9609e-01],\n",
            "        [-3.1824e-01,  1.2154e+00],\n",
            "        [ 1.4200e+00, -5.4650e-02],\n",
            "        [ 6.8388e-01, -1.3246e+00],\n",
            "        [-5.1608e-01,  6.0018e-01],\n",
            "        [-4.7022e-01, -6.0864e-01],\n",
            "        [-4.6192e-02, -1.6457e+00],\n",
            "        [-4.8333e-01, -7.4029e-01],\n",
            "        [ 3.1428e-01,  1.4156e-01],\n",
            "        [ 1.0348e+00, -6.2644e-01],\n",
            "        [-5.1509e-01,  6.9029e-01]])\n",
            "tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to create a function f that is a single TLU, meaning that it summarizes x with weights a, b, c:\n",
        "\n",
        "$ax_0+bx_1+c$\n",
        "\n",
        "In Addition we are using a *sigmoid()* function as step function.\n",
        "\n",
        "$f = \\text{sigmoid}(ax_0+bx_1+c)$"
      ],
      "metadata": {
        "id": "z267w4G48rxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, params):\n",
        "    a,b,c = params\n",
        "    return sigmoid(params[0]*x[:,0] + params[1]*x[:,1] + params[2])\n",
        "\n",
        "print(f(x, [3,-2,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NvBnCGoLPx",
        "outputId": "759d0815-3bbb-48f5-8115-040b37c316b3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.8081e-01, 9.9402e-01, 1.2862e-01, 8.2914e-01, 9.3833e-01, 3.3741e-01, 9.1350e-01, 9.7769e-01, 4.3644e-01, 2.2758e-02, 7.2315e-02, 8.5750e-01, 2.6702e-04, 7.8163e-01, 8.8992e-01, 9.2183e-01,\n",
            "        3.5801e-01, 7.6444e-01, 8.5564e-01, 9.4256e-01, 8.9164e-03, 3.3749e-01, 7.9656e-02, 1.7109e-01, 2.6388e-01, 9.9716e-01, 9.8428e-01, 8.3706e-01, 6.2703e-01, 2.4596e-01, 9.5732e-01, 2.0639e-02,\n",
            "        9.9158e-01, 1.5892e-01, 8.2850e-01, 5.1548e-01, 2.5448e-01, 6.6648e-01, 8.3189e-01, 1.8732e-02, 6.5145e-01, 8.0053e-01, 7.7991e-01, 9.7823e-01, 9.5768e-01, 9.9272e-01, 9.9108e-01, 8.7845e-01,\n",
            "        9.8388e-01, 9.9845e-01, 1.4106e-01, 4.9892e-01, 5.1103e-01, 1.0970e-01, 9.2679e-01, 9.7147e-01, 4.3923e-01, 9.4414e-01, 5.5315e-01, 5.3080e-01, 9.7060e-01, 9.9695e-01, 6.8815e-01, 9.9644e-01,\n",
            "        8.4858e-01, 9.9998e-01, 9.8602e-01, 2.2643e-01, 8.1900e-01, 8.3942e-01, 1.8293e-01, 9.9636e-01, 9.9286e-01, 7.9167e-01, 9.9140e-01, 9.7824e-01, 8.3383e-01, 9.5689e-01, 9.8953e-01, 9.5106e-01,\n",
            "        1.8175e-03, 9.9922e-01, 9.6597e-01, 1.8400e-01, 8.5632e-01, 9.6896e-01, 5.4381e-03, 3.4669e-01, 1.1837e-02, 1.3256e-01, 8.4280e-02, 9.9536e-01, 9.9667e-01, 1.4822e-01, 6.9139e-01, 9.8452e-01,\n",
            "        7.3703e-01, 8.4020e-01, 9.9531e-01, 1.2721e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to our TLU function, we need a loss function. Your task is to implement a absolute difference loss function, $∑|x_i-y_i|$, which counts the number of wrong guesses."
      ],
      "metadata": {
        "id": "UBiKkGKx-jVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, targets): return (preds-targets.abs()).sum()"
      ],
      "metadata": {
        "id": "cwzyy281wI7Q"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to train your single TLU with the absolute difference loss function, use the following code. Choose an appropriate step weight `lr` and try to explain what is happing in each line."
      ],
      "metadata": {
        "id": "eGVNErmbvFxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-5\n",
        "\n",
        "params = torch.randn(3).requires_grad_()\n",
        "# -> initizialize parameters to random value.\n",
        "\n",
        "def apply_step(params, prn=True):\n",
        "    preds = f(x, params) # -> calculate prediction based on function we defined earlier\n",
        "    loss = mae(preds, y) # -> calculate the overall loss \n",
        "    loss.backward() # -> calculate the gradients, how much the parameters need to change\n",
        "    params.data -= lr * params.grad.data #-> update parameters using our learning rate lr\n",
        "    params.grad = None\n",
        "    if prn: print(params);print(loss.item())\n",
        "    return preds\n",
        "\n",
        "\n",
        "for i in range(50): apply_step(params)"
      ],
      "metadata": {
        "id": "EB5TYTNmyO3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cfcefa-e9dd-4ff9-ba56-f390be6f4dd1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3061,  0.9692, -0.7811], requires_grad=True)\n",
            "-22.80692481994629\n",
            "tensor([-0.3061,  0.9692, -0.7813], requires_grad=True)\n",
            "-22.810781478881836\n",
            "tensor([-0.3061,  0.9691, -0.7815], requires_grad=True)\n",
            "-22.81463623046875\n",
            "tensor([-0.3062,  0.9691, -0.7817], requires_grad=True)\n",
            "-22.818492889404297\n",
            "tensor([-0.3062,  0.9690, -0.7819], requires_grad=True)\n",
            "-22.82234764099121\n",
            "tensor([-0.3062,  0.9690, -0.7821], requires_grad=True)\n",
            "-22.826202392578125\n",
            "tensor([-0.3062,  0.9690, -0.7823], requires_grad=True)\n",
            "-22.830059051513672\n",
            "tensor([-0.3063,  0.9689, -0.7824], requires_grad=True)\n",
            "-22.833911895751953\n",
            "tensor([-0.3063,  0.9689, -0.7826], requires_grad=True)\n",
            "-22.8377685546875\n",
            "tensor([-0.3063,  0.9688, -0.7828], requires_grad=True)\n",
            "-22.84162139892578\n",
            "tensor([-0.3063,  0.9688, -0.7830], requires_grad=True)\n",
            "-22.845478057861328\n",
            "tensor([-0.3064,  0.9687, -0.7832], requires_grad=True)\n",
            "-22.849328994750977\n",
            "tensor([-0.3064,  0.9687, -0.7834], requires_grad=True)\n",
            "-22.85318374633789\n",
            "tensor([-0.3064,  0.9686, -0.7836], requires_grad=True)\n",
            "-22.85703468322754\n",
            "tensor([-0.3064,  0.9686, -0.7838], requires_grad=True)\n",
            "-22.86088752746582\n",
            "tensor([-0.3065,  0.9686, -0.7840], requires_grad=True)\n",
            "-22.8647403717041\n",
            "tensor([-0.3065,  0.9685, -0.7842], requires_grad=True)\n",
            "-22.868593215942383\n",
            "tensor([-0.3065,  0.9685, -0.7843], requires_grad=True)\n",
            "-22.87244415283203\n",
            "tensor([-0.3065,  0.9684, -0.7845], requires_grad=True)\n",
            "-22.876296997070312\n",
            "tensor([-0.3066,  0.9684, -0.7847], requires_grad=True)\n",
            "-22.88014793395996\n",
            "tensor([-0.3066,  0.9683, -0.7849], requires_grad=True)\n",
            "-22.884000778198242\n",
            "tensor([-0.3066,  0.9683, -0.7851], requires_grad=True)\n",
            "-22.887849807739258\n",
            "tensor([-0.3066,  0.9683, -0.7853], requires_grad=True)\n",
            "-22.891700744628906\n",
            "tensor([-0.3067,  0.9682, -0.7855], requires_grad=True)\n",
            "-22.895549774169922\n",
            "tensor([-0.3067,  0.9682, -0.7857], requires_grad=True)\n",
            "-22.89940071105957\n",
            "tensor([-0.3067,  0.9681, -0.7859], requires_grad=True)\n",
            "-22.90325164794922\n",
            "tensor([-0.3067,  0.9681, -0.7861], requires_grad=True)\n",
            "-22.907100677490234\n",
            "tensor([-0.3068,  0.9680, -0.7862], requires_grad=True)\n",
            "-22.91094970703125\n",
            "tensor([-0.3068,  0.9680, -0.7864], requires_grad=True)\n",
            "-22.914796829223633\n",
            "tensor([-0.3068,  0.9680, -0.7866], requires_grad=True)\n",
            "-22.91864776611328\n",
            "tensor([-0.3068,  0.9679, -0.7868], requires_grad=True)\n",
            "-22.922494888305664\n",
            "tensor([-0.3069,  0.9679, -0.7870], requires_grad=True)\n",
            "-22.92634391784668\n",
            "tensor([-0.3069,  0.9678, -0.7872], requires_grad=True)\n",
            "-22.930192947387695\n",
            "tensor([-0.3069,  0.9678, -0.7874], requires_grad=True)\n",
            "-22.934038162231445\n",
            "tensor([-0.3069,  0.9677, -0.7876], requires_grad=True)\n",
            "-22.93788719177246\n",
            "tensor([-0.3070,  0.9677, -0.7878], requires_grad=True)\n",
            "-22.941734313964844\n",
            "tensor([-0.3070,  0.9677, -0.7879], requires_grad=True)\n",
            "-22.94558334350586\n",
            "tensor([-0.3070,  0.9676, -0.7881], requires_grad=True)\n",
            "-22.94942855834961\n",
            "tensor([-0.3070,  0.9676, -0.7883], requires_grad=True)\n",
            "-22.953277587890625\n",
            "tensor([-0.3071,  0.9675, -0.7885], requires_grad=True)\n",
            "-22.957122802734375\n",
            "tensor([-0.3071,  0.9675, -0.7887], requires_grad=True)\n",
            "-22.960966110229492\n",
            "tensor([-0.3071,  0.9674, -0.7889], requires_grad=True)\n",
            "-22.964813232421875\n",
            "tensor([-0.3071,  0.9674, -0.7891], requires_grad=True)\n",
            "-22.968658447265625\n",
            "tensor([-0.3072,  0.9673, -0.7893], requires_grad=True)\n",
            "-22.972503662109375\n",
            "tensor([-0.3072,  0.9673, -0.7895], requires_grad=True)\n",
            "-22.976346969604492\n",
            "tensor([-0.3072,  0.9673, -0.7897], requires_grad=True)\n",
            "-22.980192184448242\n",
            "tensor([-0.3072,  0.9672, -0.7898], requires_grad=True)\n",
            "-22.984039306640625\n",
            "tensor([-0.3073,  0.9672, -0.7900], requires_grad=True)\n",
            "-22.98788070678711\n",
            "tensor([-0.3073,  0.9671, -0.7902], requires_grad=True)\n",
            "-22.991724014282227\n",
            "tensor([-0.3073,  0.9671, -0.7904], requires_grad=True)\n",
            "-22.995569229125977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a line of code that counts the number of wrong predictions, rounding your predictions with *round()*."
      ],
      "metadata": {
        "id": "h5_LNc1o_o2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = f(x, params)\n",
        "mse(preds, y)\n",
        "incorrect = ((preds.round() - y).abs()).sum()\n",
        "incorrect"
      ],
      "metadata": {
        "id": "EEUhyhyDxwMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f827f4-8412-4d1f-d49f-ae5fb351348f"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(76., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    }
  ]
}